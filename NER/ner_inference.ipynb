{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json file\n",
    "f = open('intent/intent.json', 'r')\n",
    "intent_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list from json\n",
    "input = []\n",
    "intent = []\n",
    "\n",
    "for i in range(len(intent_json['intents'])):\n",
    "    for user_input in intent_json['intents'][i]['input']:\n",
    "        input.append(user_input)\n",
    "        intent.append(intent_json['intents'][i]['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stemmer and stopword remover\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "factory = StopWordRemoverFactory()\n",
    "stopwords = factory.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.remove('ok')\n",
    "stopwords.remove('oh')\n",
    "stopwords.remove('tidak')\n",
    "stopwords.remove('ya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang = pd.read_csv('lexicon/slang ke semi baku.csv')\n",
    "\n",
    "slang_replace = {}\n",
    "for i, row in enumerate(slang['slang']):\n",
    "    slang_replace[row] = slang['formal'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baku = pd.read_csv('lexicon/slang ke baku.csv')\n",
    "\n",
    "std_word_replace = {}\n",
    "for i, row in enumerate(baku['slang']):\n",
    "    std_word_replace[row] = baku['baku'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text cleaning function\n",
    "def clean_text(text):\n",
    "    new_text = []\n",
    "    text = text.lower() # Lowercase\n",
    "    # Loop each word in a sentence\n",
    "    for kata in text.split(): \n",
    "        # Keep word not in slang or standard word\n",
    "        if kata not in (slang_replace|std_word_replace): \n",
    "            new_text.append(kata) \n",
    "        # Replace non-formal word with standard word\n",
    "        elif kata in std_word_replace:\n",
    "            new_text+=std_word_replace[kata].split() \n",
    "        # Replace slang with standard word\n",
    "        elif kata in slang_replace:\n",
    "            for kata_slang in slang_replace[kata].split():\n",
    "                new_text.append(std_word_replace.get(kata_slang, kata_slang))\n",
    "    # Join words without stopwords after stemming\n",
    "    new_text = ' '.join(\n",
    "        stemmer.stem(word) for word in new_text if word not in stopwords\n",
    "    )\n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aku laper banget gatau maunya makan jeruk apa lagi meniru-niru.. daah ngelamar'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contoh = 'Aku laper banget gatau maunya makan jeruk apa lagi meniru-niru.. daah ngelamar'\n",
    "contoh.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aku lapar banget tahu mau makan jeruk apa tiru deh lamar'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kalimat = 'Aku laper banget gatau maunya makan jeruk apa lagi meniru-niru... daah ngelamar'\n",
    "clean_text(kalimat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved_model/encoder.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(sorted(x.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ktp, pas foto, password masih ketuker2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CV', 'biaya', 'daftar', 'dokumen', 'error upload', 'ktp',\n",
       "       'link sosmed', 'lowongan', 'lupa password', 'nama', 'pas foto',\n",
       "       'pengantar', 'penutup', 'qualification', 'responsibilities',\n",
       "       'salary', 'sapa', 'sertifikat', 'skck', 'timeline', 'training',\n",
       "       'transkrip-ijazah'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "ner = spacy.load('model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ner('''\n",
    "data scientist itu apa, data engineer, analis, data analyst, data analist, data science, DS, DA, DE science, analyst, engine, engineer\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data scientist\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SCIENTIST</span>\n",
       "</mark>\n",
       " itu apa, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data engineer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ENGINEER</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    analis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ANALIS</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data analyst\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ANALIS</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data analist\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ANALIS</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    data science\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SCIENTIST</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SCIENTIST</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ANALIS</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DE science\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SCIENTIST</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    analyst\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ANALIS</span>\n",
       "</mark>\n",
       ", engine, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    engineer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ENGINEER</span>\n",
       "</mark>\n",
       "</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCIENTIST\n",
      "ENGINEER\n",
      "ANALIS\n",
      "ANALIS\n",
      "ANALIS\n",
      "SCIENTIST\n",
      "SCIENTIST\n",
      "ANALIS\n",
      "SCIENTIST\n",
      "ANALIS\n",
      "ENGINEER\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(data scientist,\n",
       " data engineer,\n",
       " analis,\n",
       " data analyst,\n",
       " data analist,\n",
       " data science,\n",
       " DS,\n",
       " DA,\n",
       " DE science,\n",
       " analyst,\n",
       " engineer)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scientist'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents[0].label_.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_backend = 'https://fiktifid-bot.herokuapp.com/'\n",
    "data = {'user_input':'de?'}\n",
    "r = requests.post(URL_backend, json=data)\n",
    "resp = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['user_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENGINEER'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dok = ner(data['user_input'])\n",
    "dok.ents[0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maaf, Kak. Aku tidak mengerti chatnya...\n"
     ]
    }
   ],
   "source": [
    "label_idx = int(resp['prediction'])\n",
    "if label_idx != 1000:\n",
    "    i = 0\n",
    "    while i < len(intent_json['intents']):\n",
    "        if le.classes_[label_idx] == intent_json['intents'][i]['intent'] and (le.classes_[label_idx] != 'responsibilities' or le.classes_[label_idx] != 'qualification'):\n",
    "            response = intent_json['intents'][i]['response']\n",
    "            break\n",
    "        elif le.classes_[label_idx] == 'responsibilities':\n",
    "            if dok.ents[0].label_.lower() == \"scientist\":\n",
    "                response = [\"Berikut adalah tanggung jawab yang akan diberikan untuk posisi Data Scientist:\\n- Merancang dan mengembangkan berbagai solusi Machine Learning dan Deep Learning untuk meningkatkan pengalaman pengguna bagi konsumen\\n- Berkolaborasi dengan seluruh elemen bisnis dan bertanggung jawab untuk merencanakan solusi end-to-end berbasis data untuk menyelesaikan permasalahan bisnis\\n- Menjadi thinking partner bagi stakeholder lain untuk memperbaiki alur perjalanan data dan penggunaannya dalam operasional perusahaan, misal merancang proses feedback-loop atau human-in-the-loop untuk meningkatkan performa model secara berkelanjutan\"]\n",
    "                break\n",
    "            elif dok.ents[0].label_.lower()=='engineer':\n",
    "                response = [\"Berikut adalah tanggung jawab yang akan diberikan untuk posisi Data Engineer:\\n- Membangun dan menjaga end-to-end data pipeline dari input dan output heterogen\\n- Menangani dan mengelola data warehouse\\n- Membantu tim mentransformasikan data (ETL) dan mengembangkan proses ETL dari beberapa sumber\\n- Menganalisis dan mengorganisir data mentah \\n- Memastikan kualitas data dan integrasi data\"]\n",
    "                break\n",
    "            elif dok.ents[0].label_.lower()=='analis':\n",
    "                response = [\"Berikut adalah tanggung jawab yang akan diberikan untuk posisi Data Analyst:\\n- Mengumpulkan dan menyediakan data untuk membantu stakeholder lain meningkatkan metrik bisnis perusahaan dan retensi pelanggan\\n- Menganalisis data untuk menemukan insight yang dapat ditindaklanjuti seperti membuat funnel conversion analysis, cohort analysis, long-term trends, user segmentation, dan dapat membantu meningkatkan kinerja perusahaan dan mendukung pengambilan keputusan yang lebih baik\\n - Mengidentifikasi kebutuhan dan peluang bisnis berdasarkan data yang tersedia\"]\n",
    "                break\n",
    "        elif le.classes_[label_idx] == 'qualification':\n",
    "            if dok.ents[0].label_.lower()=='scientist':\n",
    "                response = [\"Untuk posisi Data Scientist ada beberapa kualifikasi yang harus dipenuhi:\\n1. Memiliki gelar sarjana di bidang informatika, ilmu komputer, statistika, matematika, atau bidang lain yang berhubungan\\n2. Memiliki pemahaman mendasar tentang Statistika Analitik, Machine Learning, Deep Learning untuk menyelesaikan permasalahan bisnis\\n3. Memiliki pengalaman kerja di bidang Data Science selama 1-3 tahun\\n4. Memiliki pemahaman dan pengalaman tentang Big Data\\n5. Memiliki kemampuan bekerja sama, kepemimpinan, dan problem solving yang baik\"]\n",
    "                break\n",
    "            elif dok.ents[0].label_.lower()=='engineer':\n",
    "                response = [\"Untuk posisi Data Engineer ada beberapa kualifikasi yang harus dipenuhi:\\n1. Memiliki gelar sarjana di bidang informatika, ilmu komputer, statistika, matematika, atau bidang lain yang berhubungan\\n2. Memiliki pengalaman bekerja dengan tools untuk ETL seperti AWS Glue, SSIS, Informatica, dll.\\n3. Memiliki pengalaman kerja di bidang Data Engineer selama 1-3 tahun\\n4. Memiliki pemahaman yang baik tentang ETL, SQL, dan noSQL\\n5. Memiliki kemampuan bekerja sama, kepemimpinan, dan problem solving yang baik\"]\n",
    "                break\n",
    "            elif dok.ents[0].label_.lower()=='analis':\n",
    "                response = [\"Untuk posisi Data Analyst ada beberapa kualifikasi yang harus dipenuhi:\\n1. Memiliki gelar sarjana di bidang informatika, ilmu komputer, statistika, matematika, atau bidang lain yang berhubungan\\n2. Memiliki pemahaman mendasar tentang Statistika Analitik dan Inferensial untuk mencari peluang bisnis\\n3. Memiliki pengalaman kerja di bidang Data Analyst selama 1-3 tahun\\n4. Memiliki pemahaman dan pengalaman tentang Big Data serta visualisasi dengan tools seperti Power BI, Tableau, dll.\\n5. Memiliki kemampuan bekerja sama, kepemimpinan, dan problem solving yang baik\"]\n",
    "                break\n",
    "        else:\n",
    "            i+=1\n",
    "else:\n",
    "    response = ['Maaf, Kak. Aku tidak mengerti chatnya...']\n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
